{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 UCI Digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfeat-fou already downloaded.\n",
      "mfeat-fac already downloaded.\n",
      "mfeat-kar already downloaded.\n",
      "mfeat-pix already downloaded.\n",
      "mfeat-zer already downloaded.\n",
      "mfeat-mor already downloaded.\n",
      "Feature set 1: X shape (2000, 76), y shape (2000,)\n",
      "Feature set 2: X shape (2000, 216), y shape (2000,)\n",
      "Feature set 3: X shape (2000, 64), y shape (2000,)\n",
      "Feature set 4: X shape (2000, 240), y shape (2000,)\n",
      "Feature set 5: X shape (2000, 47), y shape (2000,)\n",
      "Feature set 6: X shape (2000, 6), y shape (2000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "# Define dataset URL and filenames\n",
    "BASE_URL = \"https://archive.ics.uci.edu/ml/machine-learning-databases/mfeat/\"\n",
    "FILENAMES = {\n",
    "    \"profile\": \"mfeat-fou\",\n",
    "    \"fourier\": \"mfeat-fac\",\n",
    "    \"karhunen\": \"mfeat-kar\",\n",
    "    \"intensity\": \"mfeat-pix\",\n",
    "    \"zernike\": \"mfeat-zer\",\n",
    "    \"morphological\": \"mfeat-mor\"\n",
    "}\n",
    "\n",
    "# Define feature dimensions\n",
    "FEATURE_DIMS = {\n",
    "    \"profile\": 216,\n",
    "    \"fourier\": 76,\n",
    "    \"karhunen\": 64,\n",
    "    \"intensity\": 240,\n",
    "    \"zernike\": 47,\n",
    "    \"morphological\": 6\n",
    "}\n",
    "\n",
    "# Create a directory for the dataset\n",
    "DATA_DIR = \"uci_digits\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# Function to download the dataset\n",
    "def download_data():\n",
    "    for key, filename in FILENAMES.items():\n",
    "        file_path = os.path.join(DATA_DIR, filename)\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"Downloading {filename}...\")\n",
    "            urllib.request.urlretrieve(BASE_URL + filename, file_path)\n",
    "        else:\n",
    "            print(f\"{filename} already downloaded.\")\n",
    "download_data()\n",
    "\n",
    "# Load all six feature sets into a dictionary\n",
    "features = {key: np.loadtxt(os.path.join(DATA_DIR, filename)) for key, filename in FILENAMES.items()}\n",
    "\n",
    "# Create labels (0-9, 200 samples each)\n",
    "labels = np.repeat(np.arange(10), 200)\n",
    "\n",
    "# Convert dataset into a list of (X, y) pairs\n",
    "dataset_list = [(features[key], labels) for key in FILENAMES.keys()]\n",
    "\n",
    "# Verify dataset shapes\n",
    "feature_list = []\n",
    "label_list = []\n",
    "for i, (X, y) in enumerate(dataset_list):\n",
    "    print(f\"Feature set {i+1}: X shape {X.shape}, y shape {y.shape}\")\n",
    "    feature_list.append(X)\n",
    "    label_list.append(y)\n",
    "\n",
    "class_number = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Single view graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from tqdm import tqdm \n",
    "\n",
    "def estimate_sigma(X):\n",
    "    pairwise_dists = np.linalg.norm(X[:, np.newaxis] - X, axis=2)  # Compute pairwise L2 distances\n",
    "    sigma = np.median(pairwise_dists)  # Use the median distance as sigma\n",
    "    return sigma\n",
    "\n",
    "def compute_laplacian(S):\n",
    "    S_sym = (S.T + S) / 2  # Compute symmetric part\n",
    "    D = np.diag(S_sym.sum(axis=0))  # Compute diagonal matrix D\n",
    "    L = D - S_sym  # Compute Laplacian matrix\n",
    "    return L\n",
    "\n",
    "def update_Q(L, c):\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(L)\n",
    "    Q = eigenvectors[:, :c]\n",
    "    return Q\n",
    "\n",
    "def project_to_simplex(v):# equation (9)\n",
    "    n = len(v)\n",
    "    u = np.sort(v)[::-1] \n",
    "    cumsum_u = np.cumsum(u)\n",
    "    rho = np.where(u > (cumsum_u - 1) / (np.arange(n) + 1))[0][-1]\n",
    "    theta = (cumsum_u[rho] - 1) / (rho + 1)\n",
    "    return np.maximum(v - theta, 0)\n",
    "\n",
    "def update_S(Q, beta): # equation (9)\n",
    "    n, c = Q.shape\n",
    "    S = np.zeros((n, n))\n",
    "    \n",
    "    for j in range(n):\n",
    "        g_j = np.array([np.linalg.norm(Q[j] - Q[i])**2 for i in range(n)])\n",
    "        raw_sj = -g_j / (2 * beta)\n",
    "        S[j] = project_to_simplex(raw_sj)\n",
    "    \n",
    "    return S\n",
    "\n",
    "def make_single_view_graph(single_view_graph_X, class_number, default_beta=1.0):\n",
    "    \n",
    "    single_view_graph = []\n",
    "    \n",
    "    for i in tqdm(range(len(single_view_graph_X))):\n",
    "        \n",
    "        # init\n",
    "        beta = default_beta\n",
    "        S = update_S(single_view_graph_X[i], beta)\n",
    "        L = compute_laplacian(S)\n",
    "        Q = update_Q(L, class_number)\n",
    "\n",
    "        for j in tqdm(range(100)):\n",
    "            S = update_S(Q, beta)\n",
    "            L = compute_laplacian(S)\n",
    "            Q = update_Q(L, class_number)\n",
    "\n",
    "            L_rank = np.linalg.matrix_rank(L)\n",
    "            if L_rank == X.shape[0] - class_number:\n",
    "                tqdm.write(f\"{i}th graph end at {j}th iteration, L's rank is {L_rank}\")\n",
    "                break\n",
    "            elif L_rank > X.shape[0] - class_number:\n",
    "                beta *= 0.9 \n",
    "            else:\n",
    "                beta *= 1.1\n",
    "        single_view_graph.append(L)\n",
    "        \n",
    "    return single_view_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "single_view_graph = make_single_view_graph(feature_list, class_number)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Global view graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_W(single_view_graph):\n",
    "    W = [np.full(single_view_graph[0].shape, 1/len(single_view_graph))] * len(single_view_graph)\n",
    "    return W\n",
    "\n",
    "def init_A(single_view_graph, W):\n",
    "    A = np.sum(single_view_graph, axis=0) * W[0]\n",
    "    return A\n",
    "\n",
    "def init_P(A,c):\n",
    "    L = compute_laplacian(A)\n",
    "    P = update_Q(L, c)\n",
    "    return P\n",
    "\n",
    "def update_A(P, w_list, s_list, gamma=1.0):\n",
    "    n = P.shape[0]\n",
    "    c = P.shape[1]\n",
    "    m = len(w_list)\n",
    "\n",
    "    H = np.sum((P[:, np.newaxis, :] - P)**2, axis=2)\n",
    "    \n",
    "    A = np.zeros((n, n))\n",
    "    \n",
    "    for j in range(c):\n",
    "        h_j = H[:, j]\n",
    "    \n",
    "        sum_term = np.zeros(n)\n",
    "        for v in range(m):\n",
    "            w_jv = w_list[v][:, j]\n",
    "            s_jv = s_list[v][:, j] \n",
    "            sum_term += w_jv * s_jv  \n",
    "        intermediate = -(((gamma / 2.0) * (h_j)) - sum_term)\n",
    "        \n",
    "    A[j] = project_to_simplex(intermediate)\n",
    "\n",
    "    return A\n",
    "\n",
    "\n",
    "def update_P(L, c):\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(L)\n",
    "    Q = eigenvectors[:, :c]\n",
    "    return Q\n",
    "\n",
    "\n",
    "def compute_W(a, s_list):\n",
    "    v, n, _ = np.shape(s_list) \n",
    "    w_list = []\n",
    "\n",
    "    for i in range(v):\n",
    "        wv = np.zeros((n, n)) \n",
    "        for j in range(n):\n",
    "            Z_j = a[:,j] - s_list[i][:,j]\n",
    "            Z_j = Z_j.reshape(1, -1) \n",
    "            ZTZ_inv = np.linalg.pinv(Z_j.T @ Z_j)  # (Z_j^T Z_j)^{-1}\n",
    "            one_vector = np.ones((n, 1)) \n",
    "            w_jv = (ZTZ_inv @ one_vector) * (1 / (one_vector.T @ ZTZ_inv @ one_vector))\n",
    "            wv[:,j] = w_jv.reshape(-1) / np.sum(w_jv)\n",
    "        w_list.append(wv)\n",
    "\n",
    "    return w_list\n",
    "\n",
    "def make_global_graph(single_view_graph, class_number, default_gamma=1.0):\n",
    "    \n",
    "    # init\n",
    "    W = init_W(single_view_graph)\n",
    "    A = init_A(single_view_graph, W)\n",
    "    P = init_P(A, class_number)\n",
    "    gamma = default_gamma\n",
    "    \n",
    "    for j in tqdm(range(100)):\n",
    "        A = update_A(P, W, single_view_graph)\n",
    "        L = compute_laplacian(A)\n",
    "        P = update_P(L, class_number)\n",
    "        W = compute_W(A, single_view_graph)\n",
    "\n",
    "        tqdm.write(f\"iteration: {j}, L_rank: {np.linalg.matrix_rank(L)}, gamma: {gamma}\")\n",
    "        print(sum(W[0][:,0]))\n",
    "        L_rank = np.linalg.matrix_rank(L)\n",
    "        if L_rank == X.shape[0] - class_number:\n",
    "            tqdm.write(f\"end at {j}th iteration, L's rank is {L_rank}\")\n",
    "            break\n",
    "        elif L_rank < X.shape[0] - class_number:\n",
    "            gamma *= 0.9 \n",
    "        else:\n",
    "            gamma *= 1.1\n",
    "        \n",
    "    return L\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_graph = make_global_graph(single_view_graph, class_number)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def cluster(laplacian, n_clusters):\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(laplacian)\n",
    "    X = eigenvectors[:, :n_clusters]\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(X)\n",
    "    return kmeans.labels_\n",
    "\n",
    "# get clustering results\n",
    "single_view_graph_labels = []\n",
    "for i in range(len(single_view_graph)):\n",
    "    single_view_graph_labels.append(cluster(single_view_graph[i], class_number))\n",
    "\n",
    "global_graph_labels = cluster(global_graph, class_number)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "\n",
    "def cluster_accuracy(y_true, y_pred):\n",
    "    acc = np.mean(y_pred == y_true)\n",
    "    return acc\n",
    "\n",
    "def purity_score(y_true, y_pred):\n",
    "    contingency = contingency_matrix(y_true, y_pred)\n",
    "    return np.sum(np.amax(contingency, axis=0)) / np.sum(contingency)\n",
    "\n",
    "def pairwise_precision_recall_fscore(y_true, y_pred):\n",
    "\n",
    "    def get_pairs(labels):\n",
    "        pairs = set()\n",
    "        for label in np.unique(labels):\n",
    "            indices = np.where(labels == label)[0]\n",
    "            for i in range(len(indices)):\n",
    "                for j in range(i + 1, len(indices)):\n",
    "                    pairs.add((indices[i], indices[j]))\n",
    "        return pairs\n",
    "\n",
    "    true_pairs = get_pairs(y_true)\n",
    "    pred_pairs = get_pairs(y_pred)\n",
    "    \n",
    "    tp = len(true_pairs & pred_pairs)\n",
    "    fp = len(pred_pairs - true_pairs)\n",
    "    fn = len(true_pairs - pred_pairs)\n",
    "\n",
    "    precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "    recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "    f_score = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0\n",
    "    \n",
    "    return precision, recall, f_score\n",
    "\n",
    "def evaluate_clustering(y_true, y_pred):\n",
    "    \n",
    "    # remapping \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    assert y_true.shape == y_pred.shape\n",
    "\n",
    "    labels = np.unique(y_true)\n",
    "    pred_labels = np.unique(y_pred)\n",
    "    cost_matrix = -contingency_matrix(y_true, y_pred)\n",
    "\n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "    best_mapping = {pred_labels[col]: labels[row] for row, col in zip(row_ind, col_ind)}\n",
    "\n",
    "    y_pred_mapped = np.array([best_mapping[label] for label in y_pred])\n",
    "\n",
    "    # evaluate\n",
    "    acc = cluster_accuracy(y_true, y_pred_mapped)\n",
    "    nmi = normalized_mutual_info_score(y_true, y_pred)\n",
    "    purity = purity_score(y_true, y_pred_mapped)\n",
    "    precision, recall, f_score = pairwise_precision_recall_fscore(y_true, y_pred_mapped)\n",
    "    ari = adjusted_rand_score(y_true, y_pred_mapped)\n",
    "\n",
    "    return {\n",
    "        \"ACC\": acc,\n",
    "        \"NMI\": nmi,\n",
    "        \"Purity\": purity,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F-score\": f_score,\n",
    "        \"ARI\": ari\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = evaluate_clustering(y, global_graph_labels)\n",
    "print(metrics)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
