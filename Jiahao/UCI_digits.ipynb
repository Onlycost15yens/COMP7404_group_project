{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 UCI Digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfeat-fou already downloaded.\n",
      "mfeat-fac already downloaded.\n",
      "mfeat-kar already downloaded.\n",
      "mfeat-pix already downloaded.\n",
      "mfeat-zer already downloaded.\n",
      "mfeat-mor already downloaded.\n",
      "Feature set 1: X shape (2000, 76), y shape (2000,)\n",
      "Feature set 2: X shape (2000, 216), y shape (2000,)\n",
      "Feature set 3: X shape (2000, 64), y shape (2000,)\n",
      "Feature set 4: X shape (2000, 240), y shape (2000,)\n",
      "Feature set 5: X shape (2000, 47), y shape (2000,)\n",
      "Feature set 6: X shape (2000, 6), y shape (2000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "# Define dataset URL and filenames\n",
    "BASE_URL = \"https://archive.ics.uci.edu/ml/machine-learning-databases/mfeat/\"\n",
    "FILENAMES = {\n",
    "    \"profile\": \"mfeat-fou\",\n",
    "    \"fourier\": \"mfeat-fac\",\n",
    "    \"karhunen\": \"mfeat-kar\",\n",
    "    \"intensity\": \"mfeat-pix\",\n",
    "    \"zernike\": \"mfeat-zer\",\n",
    "    \"morphological\": \"mfeat-mor\"\n",
    "}\n",
    "\n",
    "# Define feature dimensions\n",
    "FEATURE_DIMS = {\n",
    "    \"profile\": 216,\n",
    "    \"fourier\": 76,\n",
    "    \"karhunen\": 64,\n",
    "    \"intensity\": 240,\n",
    "    \"zernike\": 47,\n",
    "    \"morphological\": 6\n",
    "}\n",
    "\n",
    "# Create a directory for the dataset\n",
    "DATA_DIR = \"uci_digits\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# Function to download the dataset\n",
    "def download_data():\n",
    "    for key, filename in FILENAMES.items():\n",
    "        file_path = os.path.join(DATA_DIR, filename)\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"Downloading {filename}...\")\n",
    "            urllib.request.urlretrieve(BASE_URL + filename, file_path)\n",
    "        else:\n",
    "            print(f\"{filename} already downloaded.\")\n",
    "download_data()\n",
    "\n",
    "# Load all six feature sets into a dictionary\n",
    "features = {key: np.loadtxt(os.path.join(DATA_DIR, filename)) for key, filename in FILENAMES.items()}\n",
    "\n",
    "# Create labels (0-9, 200 samples each)\n",
    "labels = np.repeat(np.arange(10), 200)\n",
    "\n",
    "# Convert dataset into a list of (X, y) pairs\n",
    "dataset_list = [(features[key], labels) for key in FILENAMES.keys()]\n",
    "\n",
    "# Verify dataset shapes\n",
    "feature_list = []\n",
    "label_list = []\n",
    "for i, (X, y) in enumerate(dataset_list):\n",
    "    print(f\"Feature set {i+1}: X shape {X.shape}, y shape {y.shape}\")\n",
    "    feature_list.append(X)\n",
    "    label_list.append(y)\n",
    "\n",
    "class_number = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Single view graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from tqdm import tqdm \n",
    "\n",
    "def estimate_sigma(X):\n",
    "    pairwise_dists = np.linalg.norm(X[:, np.newaxis] - X, axis=2)  # Compute pairwise L2 distances\n",
    "    sigma = np.median(pairwise_dists)  # Use the median distance as sigma\n",
    "    return sigma\n",
    "\n",
    "def compute_laplacian(S):\n",
    "    S_sym = (S.T + S) / 2  # Compute symmetric part\n",
    "    D = np.diag(S_sym.sum(axis=0))  # Compute diagonal matrix D\n",
    "    L = D - S_sym  # Compute Laplacian matrix\n",
    "    return L\n",
    "\n",
    "def update_Q(L, c):\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(L)\n",
    "    Q = eigenvectors[:, :c]\n",
    "    return Q\n",
    "\n",
    "def project_to_simplex(v):# equation (9)\n",
    "    n = len(v)\n",
    "    u = np.sort(v)[::-1] \n",
    "    cumsum_u = np.cumsum(u)\n",
    "    rho = np.where(u > (cumsum_u - 1) / (np.arange(n) + 1))[0][-1]\n",
    "    theta = (cumsum_u[rho] - 1) / (rho + 1)\n",
    "    return np.maximum(v - theta, 0)\n",
    "\n",
    "def update_S(Q, beta): # equation (9)\n",
    "    n, c = Q.shape\n",
    "    S = np.zeros((n, n))\n",
    "    \n",
    "    for j in range(n):\n",
    "        g_j = np.array([np.linalg.norm(Q[j] - Q[i])**2 for i in range(n)])\n",
    "        raw_sj = -g_j / (2 * beta)\n",
    "        S[j] = project_to_simplex(raw_sj)\n",
    "    \n",
    "    return S\n",
    "\n",
    "def make_single_view_graph(single_view_graph_X, class_number, default_beta=1.0):\n",
    "    \n",
    "    single_view_graph = []\n",
    "    \n",
    "    for i in tqdm(range(len(single_view_graph_X))):\n",
    "        \n",
    "        # init\n",
    "        beta = default_beta\n",
    "        S = update_S(single_view_graph_X[i], beta)\n",
    "        L = compute_laplacian(S)\n",
    "        Q = update_Q(L, class_number)\n",
    "\n",
    "        for j in tqdm(range(100)):\n",
    "            S = update_S(Q, beta)\n",
    "            L = compute_laplacian(S)\n",
    "            Q = update_Q(L, class_number)\n",
    "\n",
    "            L_rank = np.linalg.matrix_rank(L)\n",
    "            if L_rank == X.shape[0] - class_number:\n",
    "                tqdm.write(f\"{i+1}th graph end at {j}th iteration, L's rank is {L_rank}\")\n",
    "                break\n",
    "            elif L_rank > X.shape[0] - class_number:\n",
    "                beta *= 0.9 \n",
    "            else:\n",
    "                beta *= 1.1\n",
    "        single_view_graph.append(L)\n",
    "        \n",
    "    return single_view_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                     \n",
      " 12%|█▏        | 12/100 [03:35<26:18, 17.94s/it]\n",
      " 17%|█▋        | 1/6 [03:44<18:41, 224.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th graph end at 12th iteration, L's rank is 1990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                              \n",
      "  7%|▋         | 7/100 [01:57<26:07, 16.85s/it]\n",
      " 33%|███▎      | 2/6 [05:51<11:07, 167.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th graph end at 7th iteration, L's rank is 1990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                              \n",
      "  7%|▋         | 7/100 [01:50<24:32, 15.83s/it]\n",
      " 50%|█████     | 3/6 [07:50<07:15, 145.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2th graph end at 7th iteration, L's rank is 1990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                              \n",
      "  7%|▋         | 7/100 [02:01<26:54, 17.36s/it]\n",
      " 67%|██████▋   | 4/6 [10:00<04:38, 139.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3th graph end at 7th iteration, L's rank is 1990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                              \n",
      " 11%|█         | 11/100 [02:58<24:00, 16.19s/it]\n",
      " 83%|████████▎ | 5/6 [13:08<02:36, 156.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4th graph end at 11th iteration, L's rank is 1990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                              \n",
      " 12%|█▏        | 12/100 [03:18<24:18, 16.57s/it]\n",
      "100%|██████████| 6/6 [16:36<00:00, 166.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5th graph end at 12th iteration, L's rank is 1990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "single_view_graph = make_single_view_graph(feature_list, class_number)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Global view graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_W(single_view_graph):\n",
    "    W = [np.full(single_view_graph[0].shape, 1/len(single_view_graph))] * len(single_view_graph)\n",
    "    return W\n",
    "\n",
    "def init_A(single_view_graph, W):\n",
    "    A = np.sum(single_view_graph, axis=0) * W[0]\n",
    "    return A\n",
    "\n",
    "def init_P(A,c):\n",
    "    L = compute_laplacian(A)\n",
    "    P = update_Q(L, c)\n",
    "    return P\n",
    "\n",
    "def update_A(P, w_list, s_list, gamma=1.0):\n",
    "    n = P.shape[0]\n",
    "    c = P.shape[1]\n",
    "    m = len(w_list)\n",
    "\n",
    "    H = np.sum((P[:, np.newaxis, :] - P)**2, axis=2)\n",
    "    \n",
    "    A = np.zeros((n, n))\n",
    "    \n",
    "    for j in range(c):\n",
    "        h_j = H[:, j]\n",
    "    \n",
    "        sum_term = np.zeros(n)\n",
    "        for v in range(m):\n",
    "            w_jv = w_list[v][:, j]\n",
    "            s_jv = s_list[v][:, j] \n",
    "            sum_term += w_jv * s_jv  \n",
    "        intermediate = -(((gamma / 2.0) * (h_j)) - sum_term)\n",
    "        \n",
    "    A[j] = project_to_simplex(intermediate)\n",
    "\n",
    "    return A\n",
    "\n",
    "\n",
    "def update_P(L, c):\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(L)\n",
    "    Q = eigenvectors[:, :c]\n",
    "    return Q\n",
    "\n",
    "\n",
    "def compute_W(a, s_list):\n",
    "    v, n, _ = np.shape(s_list) \n",
    "    w_list = []\n",
    "\n",
    "    for i in range(v):\n",
    "        wv = np.zeros((n, n)) \n",
    "        for j in range(n):\n",
    "            Z_j = a[:,j] - s_list[i][:,j]\n",
    "            Z_j = Z_j.reshape(1, -1) \n",
    "            ZTZ_inv = np.linalg.pinv(Z_j.T @ Z_j)  # (Z_j^T Z_j)^{-1}\n",
    "            one_vector = np.ones((n, 1)) \n",
    "            w_jv = (ZTZ_inv @ one_vector) * (1 / (one_vector.T @ ZTZ_inv @ one_vector))\n",
    "            wv[:,j] = w_jv.reshape(-1) / np.sum(w_jv)\n",
    "        w_list.append(wv)\n",
    "\n",
    "    return w_list\n",
    "\n",
    "def make_global_graph(single_view_graph, class_number, default_gamma=1.0):\n",
    "    \n",
    "    # init\n",
    "    W = init_W(single_view_graph)\n",
    "    A = init_A(single_view_graph, W)\n",
    "    P = init_P(A, class_number)\n",
    "    gamma = default_gamma\n",
    "    print(\"init finished\")\n",
    "    \n",
    "    for j in tqdm(range(100)):\n",
    "        A = update_A(P, W, single_view_graph)\n",
    "        print(\"A finished\")\n",
    "        L = compute_laplacian(A)\n",
    "        print(\"L finished\")\n",
    "        P = update_P(L, class_number)\n",
    "        print(\"P finished\")\n",
    "        W = compute_W(A, single_view_graph)\n",
    "        print(\"W finished\")\n",
    "\n",
    "        tqdm.write(f\"iteration: {j}, L_rank: {np.linalg.matrix_rank(L)}, gamma: {gamma}\")\n",
    "        L_rank = np.linalg.matrix_rank(L)\n",
    "        if L_rank == X.shape[0] - class_number:\n",
    "            tqdm.write(f\"end at {j}th iteration, L's rank is {L_rank}\")\n",
    "            break\n",
    "        elif L_rank < X.shape[0] - class_number:\n",
    "            gamma *= 0.9 \n",
    "        else:\n",
    "            gamma *= 1.1\n",
    "        \n",
    "    return L\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A finished\n",
      "L finished\n",
      "P finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [1:07:55<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m global_graph \u001b[38;5;241m=\u001b[39m make_global_graph(single_view_graph, class_number)\n",
      "Cell \u001b[0;32mIn[15], line 77\u001b[0m, in \u001b[0;36mmake_global_graph\u001b[0;34m(single_view_graph, class_number, default_gamma)\u001b[0m\n\u001b[1;32m     75\u001b[0m P \u001b[38;5;241m=\u001b[39m update_P(L, class_number)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP finished\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 77\u001b[0m W \u001b[38;5;241m=\u001b[39m compute_W(A, single_view_graph)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW finished\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     80\u001b[0m tqdm\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, L_rank: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mmatrix_rank(L)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, gamma: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgamma\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[15], line 53\u001b[0m, in \u001b[0;36mcompute_W\u001b[0;34m(a, s_list)\u001b[0m\n\u001b[1;32m     51\u001b[0m Z_j \u001b[38;5;241m=\u001b[39m a[:,j] \u001b[38;5;241m-\u001b[39m s_list[i][:,j]\n\u001b[1;32m     52\u001b[0m Z_j \u001b[38;5;241m=\u001b[39m Z_j\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \n\u001b[0;32m---> 53\u001b[0m ZTZ_inv \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mpinv(Z_j\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m Z_j)  \u001b[38;5;66;03m# (Z_j^T Z_j)^{-1}\u001b[39;00m\n\u001b[1;32m     54\u001b[0m one_vector \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((n, \u001b[38;5;241m1\u001b[39m)) \n\u001b[1;32m     55\u001b[0m w_jv \u001b[38;5;241m=\u001b[39m (ZTZ_inv \u001b[38;5;241m@\u001b[39m one_vector) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m (one_vector\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m ZTZ_inv \u001b[38;5;241m@\u001b[39m one_vector))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/numpy/linalg/linalg.py:2022\u001b[0m, in \u001b[0;36mpinv\u001b[0;34m(a, rcond, hermitian)\u001b[0m\n\u001b[1;32m   2020\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m wrap(res)\n\u001b[1;32m   2021\u001b[0m a \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mconjugate()\n\u001b[0;32m-> 2022\u001b[0m u, s, vt \u001b[38;5;241m=\u001b[39m svd(a, full_matrices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, hermitian\u001b[38;5;241m=\u001b[39mhermitian)\n\u001b[1;32m   2024\u001b[0m \u001b[38;5;66;03m# discard small singular values\u001b[39;00m\n\u001b[1;32m   2025\u001b[0m cutoff \u001b[38;5;241m=\u001b[39m rcond[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, newaxis] \u001b[38;5;241m*\u001b[39m amax(s, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/numpy/linalg/linalg.py:1681\u001b[0m, in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, hermitian)\u001b[0m\n\u001b[1;32m   1678\u001b[0m         gufunc \u001b[38;5;241m=\u001b[39m _umath_linalg\u001b[38;5;241m.\u001b[39msvd_n_s\n\u001b[1;32m   1680\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->DdD\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->ddd\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 1681\u001b[0m u, s, vh \u001b[38;5;241m=\u001b[39m gufunc(a, signature\u001b[38;5;241m=\u001b[39msignature, extobj\u001b[38;5;241m=\u001b[39mextobj)\n\u001b[1;32m   1682\u001b[0m u \u001b[38;5;241m=\u001b[39m u\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1683\u001b[0m s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mastype(_realType(result_t), copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "global_graph = make_global_graph(single_view_graph, class_number)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def cluster(laplacian, n_clusters):\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(laplacian)\n",
    "    X = eigenvectors[:, :n_clusters]\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(X)\n",
    "    return kmeans.labels_\n",
    "\n",
    "# get clustering results\n",
    "single_view_graph_labels = []\n",
    "for i in range(len(single_view_graph)):\n",
    "    single_view_graph_labels.append(cluster(single_view_graph[i], class_number))\n",
    "\n",
    "global_graph_labels = cluster(global_graph, class_number)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "\n",
    "def cluster_accuracy(y_true, y_pred):\n",
    "    acc = np.mean(y_pred == y_true)\n",
    "    return acc\n",
    "\n",
    "def purity_score(y_true, y_pred):\n",
    "    contingency = contingency_matrix(y_true, y_pred)\n",
    "    return np.sum(np.amax(contingency, axis=0)) / np.sum(contingency)\n",
    "\n",
    "def pairwise_precision_recall_fscore(y_true, y_pred):\n",
    "\n",
    "    def get_pairs(labels):\n",
    "        pairs = set()\n",
    "        for label in np.unique(labels):\n",
    "            indices = np.where(labels == label)[0]\n",
    "            for i in range(len(indices)):\n",
    "                for j in range(i + 1, len(indices)):\n",
    "                    pairs.add((indices[i], indices[j]))\n",
    "        return pairs\n",
    "\n",
    "    true_pairs = get_pairs(y_true)\n",
    "    pred_pairs = get_pairs(y_pred)\n",
    "    \n",
    "    tp = len(true_pairs & pred_pairs)\n",
    "    fp = len(pred_pairs - true_pairs)\n",
    "    fn = len(true_pairs - pred_pairs)\n",
    "\n",
    "    precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "    recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "    f_score = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0\n",
    "    \n",
    "    return precision, recall, f_score\n",
    "\n",
    "def evaluate_clustering(y_true, y_pred):\n",
    "    \n",
    "    # remapping \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    assert y_true.shape == y_pred.shape\n",
    "\n",
    "    labels = np.unique(y_true)\n",
    "    pred_labels = np.unique(y_pred)\n",
    "    cost_matrix = -contingency_matrix(y_true, y_pred)\n",
    "\n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "    best_mapping = {pred_labels[col]: labels[row] for row, col in zip(row_ind, col_ind)}\n",
    "\n",
    "    y_pred_mapped = np.array([best_mapping[label] for label in y_pred])\n",
    "\n",
    "    # evaluate\n",
    "    acc = cluster_accuracy(y_true, y_pred_mapped)\n",
    "    nmi = normalized_mutual_info_score(y_true, y_pred)\n",
    "    purity = purity_score(y_true, y_pred_mapped)\n",
    "    precision, recall, f_score = pairwise_precision_recall_fscore(y_true, y_pred_mapped)\n",
    "    ari = adjusted_rand_score(y_true, y_pred_mapped)\n",
    "\n",
    "    return {\n",
    "        \"ACC\": acc,\n",
    "        \"NMI\": nmi,\n",
    "        \"Purity\": purity,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F-score\": f_score,\n",
    "        \"ARI\": ari\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ACC': 0.1005, 'NMI': 0.008930414963807663, 'Purity': 0.1045, 'Precision': 0.09956613807359248, 'Recall': 0.9911809045226131, 'F-score': 0.18095498028710416, 'ARI': 3.630807355022272e-05}\n"
     ]
    }
   ],
   "source": [
    "metrics = evaluate_clustering(labels, single_view_graph_labels[1])\n",
    "print(metrics)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
